# **멀티턴(Multi-turn) 대화란?**

> **AI가 한 번의 질문(1턴)만 보고 답하는 게 아니라,  
> 이전 질문·답변들을 모두 기억하면서  
> 여러 턴(turn)의 대화를 이어가는 방식**입니다.

즉,

- 질문 → 답변 (1턴)
    
- 추가 질문 → 답변 (2턴)
    
- 또 질문 → 답변 (3턴)  
    이렇게 **대화가 여러 단계로 이어지며**, 앞서 나온 내용을 참고해 문맥을 유지하는 구조입니다.
    

---

# 🆚 싱글턴(Single-turn)과 비교해서 보면 더 쉬움

|구분|설명|
|---|---|
|**싱글턴(Single-turn)**|매번 대화를 “처음 보는 질문”처럼 처리 → 과거 맥락 없음|
|**멀티턴(Multi-turn)**|이전의 모든 대화 내용을 기억·활용하여 적절한 답변 생성|

예시:

### 🔹 Single-turn AI

사용자: “파이썬 코드 예제로 설명해줘.”  
AI: “무슨 코드인가요?” → 과거 대화 기억 ❌

### 🔹 Multi-turn AI

사용자: “방금 이야기한 AES 암호화 예제를 파이썬으로 보여줘.”  
AI: → 이전 AES 대화 내용을 기억하고 거기에 맞춰 답변 생성  
→ 문맥 이해 O

---

# 🚀 왜 멀티턴이 중요할까?

### 1) **문맥(Context)을 이해할 수 있음**

사용자가 “그거 다시 설명해줘”, “이 부분만 수정해줘”라고 해도  
AI는 과거 대화의 내용을 이해하고 답변 가능.

### 2) **복잡한 문제 해결 가능**

보안, 암호화, RAG 아키텍처처럼  
단일 질문으로 해결하기 어려운 문제도  
여러 단계의 대화로 점차 좁혀가는 방식이 가능.

### 3) **에이전트(Agentic) 시스템의 기본 요소**

- LangChain
    
- LangGraph
    
- OpenAI MCP  
    이런 에이전트 프레임워크는 모두  
    “멀티턴 기반 + 기억 + 반복적인 Tool 사용”을 핵심으로 함.
    

---

# 🧩 멀티턴 대화의 내부 구조(LLM 입장에서)

LLM은 매 턴마다 아래를 입력받음:

`[대화 히스토리 전체] + [현재 사용자 발화]`

그래서 이렇게 작동해요:

1. 유저: A를 설명해줘
    
2. AI: A 설명
    
3. 유저: 그럼 B는?  
    → AI는 “그럼(B)”이라는 말이 A의 맥락과 연결된 걸 자동으로 이해함  
    → A+B 관계를 유지한 답변 생성
    

만약 히스토리를 제거하면, 멀티턴 능력도 사라짐.

---

# 🔥 한 줄 요약

> **멀티턴 대화 = AI가 과거 대화를 기억하며 자연스러운 지속 대화를 수행하는 기술.  
> 문맥 유지, 추론 연결, 복잡한 질의 응답에 필수.**